{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Flow Diagnostics (MAF/MADE/RQS)\n",
    "\n",
    "**Ziel:** Belastbar testen, ob und wie stark die Konditionierung \\(\\mathbf{X}\\) in deinem Flow \\(p(\\mathbf{Y}\\mid\\mathbf{X})\\) greift – skaliert auf viele (z. B. 20) Kontext-Features.\n",
    "\n",
    "**Checks:**\n",
    "1. **Permutation-Importance (ΔNLL)** je Kontext-Feature  \n",
    "2. **Gradienten‑Sensitivität** von \\(\\log p(\\mathbf{Y}\\mid\\mathbf{X})\\) w.r.t. \\(\\mathbf{X}\\)  \n",
    "3. **Counterfactual‑Sampling** (kleine Δ in einem Feature → sichtbarer Shift in Y‑Verteilung)  \n",
    "4. **All‑Shuffle Sanity Check** (alle Kontexte permutieren → NLL muss hochgehen)\n",
    "\n",
    "> **Seaborn-Hinweis:** In dieser generierten Version werden Plots mit **matplotlib** erstellt.  \n",
    "> Wenn du lokal **seaborn** nutzen willst, kannst du einfach die kommentierten `import seaborn as sns`/`sns.set()`‑Zeilen aktivieren und die Plot-Funktionen minimal anpassen."
   ],
   "id": "cd173e37ff60127a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T07:51:00.587501Z",
     "start_time": "2025-10-13T07:50:58.565551Z"
    }
   },
   "source": [
    "# --- Imports ---\n",
    "import math, json, os\n",
    "import numpy as np\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import argparse\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Optional (lokal aktivierbar):\n",
    "# import seaborn as sns\n",
    "# sns.set()"
   ],
   "id": "bc6e43f9897a6235",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T07:51:05.724743Z",
     "start_time": "2025-10-13T07:51:05.722624Z"
    }
   },
   "source": [
    "# --- Konfiguration (anpassbar) ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE_EVAL = 4096\n",
    "PERM_REPEATS = 2           # wie oft eine Spalte permutiert wird\n",
    "COUNTERFACTUAL_DELTA = 0.1 # Schrittweite für Δx_j\n",
    "TOPK = 5                   # wie viele Top-Features wir detailliert anschauen\n",
    "USE_AMP = False            # für Diagnostik besser aus\n",
    "PRINT_WIDTH = 120"
   ],
   "id": "2016e0ffe99b044e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T07:51:11.947379Z",
     "start_time": "2025-10-13T07:51:11.845394Z"
    }
   },
   "source": [
    "# --- Utility-Funktionen ---\n",
    "@torch.no_grad()\n",
    "def mean_nll(model, Y, X, bs=4096, use_amp=False, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    tot, n = 0.0, 0\n",
    "    X = X.to(device)\n",
    "    Y = Y.to(device)\n",
    "    autocast_ctx = (torch.amp.autocast(device_type=\"cuda\") if (use_amp and device==\"cuda\") else nullcontext())\n",
    "    for i in range(0, X.size(0), bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        with autocast_ctx:\n",
    "            nll = -model.log_probs(yb, xb)  # shape [B,1]\n",
    "        tot += nll.sum().item()\n",
    "        n += yb.size(0)\n",
    "    return tot / max(n,1)\n",
    "\n",
    "def perm_importance(model, Y, X, col_names, repeats=3, bs=4096, use_amp=False, device=\"cpu\", rng=None):\n",
    "    base = mean_nll(model, Y, X, bs, use_amp, device)\n",
    "    deltas = {}\n",
    "    Xcpu = X.detach().cpu()\n",
    "    N = Xcpu.shape[0]\n",
    "    rng = np.random.default_rng(None if rng is None else rng)\n",
    "    for j, name in enumerate(col_names):\n",
    "        incs = []\n",
    "        for _ in range(repeats):\n",
    "            Xperm = Xcpu.clone()\n",
    "            idx = torch.from_numpy(rng.permutation(N))\n",
    "            Xperm[:, j] = Xperm[idx, j]   # nur Spalte j mischen\n",
    "            inc = mean_nll(model, Y, Xperm.to(device), bs, use_amp, device) - base\n",
    "            incs.append(float(inc))\n",
    "        deltas[name] = (float(np.mean(incs)), float(np.std(incs)))\n",
    "    return base, deltas\n",
    "\n",
    "def all_shuffle_nll(model, Y, X, bs=4096, use_amp=False, device=\"cpu\", rng=None):\n",
    "    rng = np.random.default_rng(None if rng is None else rng)\n",
    "    Xcpu = X.detach().cpu().clone()\n",
    "    N = Xcpu.shape[0]\n",
    "    # jede Spalte unabhängig permutieren\n",
    "    for j in range(Xcpu.shape[1]):\n",
    "        idx = torch.from_numpy(rng.permutation(N))\n",
    "        Xcpu[:, j] = Xcpu[idx, j]\n",
    "    return mean_nll(model, Y, Xcpu.to(device), bs, use_amp, device)\n",
    "\n",
    "def context_grad_sensitivity(model, Y, X, bs=2048, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    grads_sum = torch.zeros(X.size(1), device=device)\n",
    "    count = 0\n",
    "    for i in range(0, X.size(0), bs):\n",
    "        xb = X[i:i+bs].to(device).detach().requires_grad_(True)\n",
    "        yb = Y[i:i+bs].to(device)\n",
    "        lp = model.log_probs(yb, xb).mean()   # scalar\n",
    "        g, = torch.autograd.grad(lp, xb, retain_graph=False, create_graph=False)\n",
    "        grads_sum += g.abs().mean(dim=0)\n",
    "        count += 1\n",
    "    return (grads_sum / max(count,1)).detach().cpu()  # Größe [C]\n",
    "\n",
    "@torch.no_grad()\n",
    "def counterfactual_shift(model, X, j, delta, sample_bs=8192, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    N = X.size(0)\n",
    "    # a) Original-Samples\n",
    "    Ys = []\n",
    "    for i in range(0, N, sample_bs):\n",
    "        xb = X[i:i+sample_bs].to(device)\n",
    "        Ys.append(model.sample(num_samples=xb.size(0), cond_inputs=xb))  # [B,Dy]\n",
    "    Y0 = torch.cat(Ys, dim=0).cpu()\n",
    "\n",
    "    # b) Perturbierte Kontexte\n",
    "    Xp = X.clone()\n",
    "    Xp[:, j] += delta\n",
    "    Ys = []\n",
    "    for i in range(0, N, sample_bs):\n",
    "        xb = Xp[i:i+sample_bs].to(device)\n",
    "        Ys.append(model.sample(num_samples=xb.size(0), cond_inputs=xb))\n",
    "    Y1 = torch.cat(Ys, dim=0).cpu()\n",
    "\n",
    "    mean_shift = (Y1.mean(dim=0) - Y0.mean(dim=0))       # [Dy]\n",
    "    var_shift  = (Y1.var(dim=0, unbiased=False) - Y0.var(dim=0, unbiased=False))  # [Dy]\n",
    "    return mean_shift, var_shift\n",
    "\n",
    "def topk_by_delta(deltas, k=5):\n",
    "    arr = [(name, v[0], v[1]) for name, v in deltas.items()]\n",
    "    arr.sort(key=lambda t: t[1], reverse=True)  # nach ΔNLL-mean absteigend\n",
    "    return arr[:k], arr\n",
    "\n",
    "def print_table(rows, headers):\n",
    "    colw = [max(len(str(h)), *(len(str(r[i])) for r in rows)) for i,h in enumerate(headers)]\n",
    "    fmt = \" | \".join(\"{:%d}\"%w for w in colw)\n",
    "    line = \"-+-\".join(\"-\"*w for w in colw)\n",
    "    print(fmt.format(*headers))\n",
    "    print(line)\n",
    "    for r in rows:\n",
    "        print(fmt.format(*r))\n",
    "\n",
    "# --- Plot-Funktionen (matplotlib-only) ---\n",
    "def barplot_perm_importance(deltas, title=\"Permutation Importance (ΔNLL)\", figsize=(10, 5)):\n",
    "    names = list(deltas.keys())\n",
    "    vals  = [deltas[n][0] for n in names]\n",
    "    errs  = [deltas[n][1] for n in names]\n",
    "    idx = np.arange(len(names))\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(idx, vals, yerr=errs)\n",
    "    plt.xticks(idx, names, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"ΔNLL (↑ schlimmer)\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def barplot_grad_sensitivity(names, grads, title=\"Gradient Sensitivity ⟨|∂ log p/∂x_j|⟩\", figsize=(10,5)):\n",
    "    idx = np.arange(len(names))\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(idx, grads)\n",
    "    plt.xticks(idx, names, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"⟨|∂ log p/∂x_j|⟩\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def mean_var_shift_plot(mean_shift, var_shift, out_names=None, title=\"Counterfactual Shift (Δx_j)\", figsize=(10,6)):\n",
    "    Dy = mean_shift.numel()\n",
    "    xs = np.arange(Dy)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(xs, mean_shift.numpy(), marker=\"o\", linestyle=\"-\", label=\"Δ mean(Y)\")\n",
    "    plt.plot(xs, var_shift.numpy(),  marker=\"s\", linestyle=\"--\", label=\"Δ var(Y)\")\n",
    "    if out_names is not None and len(out_names)==Dy:\n",
    "        plt.xticks(xs, out_names, rotation=45, ha=\"right\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Output-Dimension\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "27d206a80d7a6d42",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T07:51:19.229974Z",
     "start_time": "2025-10-13T07:51:19.224169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_config_and_parser(system_path):\n",
    "    now = datetime.now()\n",
    "    if get_os() == \"Mac\":\n",
    "        print(\"load MAC config-file\")\n",
    "        config_file_name_classifier = \"MAC_run_classifier.cfg\"\n",
    "        config_file_name_flow = \"MAC_run_flow.cfg\"\n",
    "    elif get_os() == \"Linux\":\n",
    "        print(\"load LMU config-file\")\n",
    "        config_file_name_classifier = \"LMU_run_classifier.cfg\"\n",
    "        config_file_name_flow = \"LMU_run_flow.cfg\"\n",
    "    else:\n",
    "        print(\"Undefined operating system\")\n",
    "        sys.exit()\n",
    "\n",
    "    parser_classifier = argparse.ArgumentParser(description='Start gaNdalF')\n",
    "    parser_classifier.add_argument(\n",
    "        '--config_filename',\n",
    "        \"-cf\",\n",
    "        type=str,\n",
    "        nargs=1,\n",
    "        required=False,\n",
    "        default=config_file_name_classifier,\n",
    "        help='Name of config file. If not given default.cfg will be used'\n",
    "    )\n",
    "    args_classifier = parser_classifier.parse_args()\n",
    "    if isinstance(args_classifier.config_filename, list):\n",
    "        args_classifier.config_filename = args_classifier.config_filename[0]\n",
    "    with open(f\"{system_path}/conf/{args_classifier.config_filename}\", 'r') as fp:\n",
    "        print(f\"open {f'{system_path}/conf/{args_classifier.config_filename}'}\")\n",
    "        config_classifier = yaml.safe_load(fp)\n",
    "    config_classifier['RUN_DATE'] = now.strftime('%Y-%m-%d_%H-%M')\n",
    "\n",
    "    parser_flow = argparse.ArgumentParser(description='Start gaNdalF')\n",
    "    parser_flow.add_argument(\n",
    "        '--config_filename',\n",
    "        \"-cf\",\n",
    "        type=str,\n",
    "        nargs=1,\n",
    "        required=False,\n",
    "        default=config_file_name_flow,\n",
    "        help='Name of config file. If not given default.cfg will be used'\n",
    "    )\n",
    "    args_flow = parser_flow.parse_args()\n",
    "    if isinstance(args_flow.config_filename, list):\n",
    "        args_flow.config_filename = args_flow.config_filename[0]\n",
    "    with open(f\"{system_path}/conf/{args_flow.config_filename}\", 'r') as fp:\n",
    "        print(f\"open {f'{system_path}/conf/{args_flow.config_filename}'}\")\n",
    "        config_flow = yaml.safe_load(fp)\n",
    "    config_flow['RUN_DATE'] = now.strftime('%Y-%m-%d_%H-%M')\n",
    "\n",
    "    return config_classifier, config_flow"
   ],
   "id": "bf41195d3f37ba5f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T07:53:36.361645Z",
     "start_time": "2025-10-13T07:53:36.193344Z"
    }
   },
   "source": [
    "from Handler import fnn, get_os, unsheared_shear_cuts, unsheared_mag_cut, LoggerHandler, plot_features, plot_binning_statistics_combined, plot_balrog_histogram_with_error, plot_compare_corner, calc_color\n",
    "from gandalf import gaNdalF\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "classifier_cfg, flow_cfg = load_config_and_parser(system_path=os.path.abspath(sys.path[0]))\n",
    "\n",
    "log_lvl = logging.INFO\n",
    "if flow_cfg[\"LOGGING_LEVEL\"] == \"DEBUG\":\n",
    "    log_lvl = logging.DEBUG\n",
    "elif flow_cfg[\"LOGGING_LEVEL\"] == \"ERROR\":\n",
    "    log_lvl = logging.ERROR\n",
    "\n",
    "run_flow_logger = LoggerHandler(\n",
    "    logger_dict={\"logger_name\": \"train flow logger\",\n",
    "                 \"info_logger\": flow_cfg['INFO_LOGGER'],\n",
    "                 \"error_logger\": flow_cfg['ERROR_LOGGER'],\n",
    "                 \"debug_logger\": flow_cfg['DEBUG_LOGGER'],\n",
    "                 \"stream_logger\": flow_cfg['STREAM_LOGGER'],\n",
    "                 \"stream_logging_level\": log_lvl},\n",
    "    log_folder_path=f\"{flow_cfg['PATH_OUTPUT']}/\"\n",
    ")\n",
    "\n",
    "flow_model = gaNdalF(run_flow_logger, classifier_cfg=classifier_cfg, flow_cfg=flow_cfg)\n",
    "# df_gandalf, df_balrog = flow_model.run_flow()\n",
    "\n",
    "df_balrog = flow_model.galaxies.test_dataset\n",
    "col_in  = flow_cfg[\"INPUT_COLS\"]\n",
    "col_out = flow_cfg[\"OUTPUT_COLS\"]\n",
    "X_valid = torch.tensor(df_balrog[col_in].values, dtype=next(flow_model.parameters()).dtype)\n",
    "Y_valid = torch.tensor(df_balrog[col_out].values, dtype=next(flow_model.parameters()).dtype)\n",
    "names_in = list(col_in)\n",
    "names_out = list(col_out)"
   ],
   "id": "16a60b3a39831ea8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load MAC config-file\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m pd\u001B[38;5;241m.\u001B[39mset_option(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisplay.max_columns\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m pd\u001B[38;5;241m.\u001B[39mset_option(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisplay.max_rows\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m----> 6\u001B[0m classifier_cfg, flow_cfg \u001B[38;5;241m=\u001B[39m \u001B[43mload_config_and_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43msystem_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m log_lvl \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mINFO\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m flow_cfg[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLOGGING_LEVEL\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDEBUG\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "Cell \u001B[0;32mIn[4], line 25\u001B[0m, in \u001B[0;36mload_config_and_parser\u001B[0;34m(system_path)\u001B[0m\n\u001B[1;32m     15\u001B[0m parser_classifier \u001B[38;5;241m=\u001B[39m argparse\u001B[38;5;241m.\u001B[39mArgumentParser(description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStart gaNdalF\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     16\u001B[0m parser_classifier\u001B[38;5;241m.\u001B[39madd_argument(\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--config_filename\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-cf\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m     help\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mName of config file. If not given default.cfg will be used\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     24\u001B[0m )\n\u001B[0;32m---> 25\u001B[0m args_classifier \u001B[38;5;241m=\u001B[39m \u001B[43mparser_classifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(args_classifier\u001B[38;5;241m.\u001B[39mconfig_filename, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m     27\u001B[0m     args_classifier\u001B[38;5;241m.\u001B[39mconfig_filename \u001B[38;5;241m=\u001B[39m args_classifier\u001B[38;5;241m.\u001B[39mconfig_filename[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/argparse.py:1829\u001B[0m, in \u001B[0;36mArgumentParser.parse_args\u001B[0;34m(self, args, namespace)\u001B[0m\n\u001B[1;32m   1827\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m argv:\n\u001B[1;32m   1828\u001B[0m     msg \u001B[38;5;241m=\u001B[39m _(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munrecognized arguments: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1829\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43margv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1830\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m args\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/argparse.py:2585\u001B[0m, in \u001B[0;36mArgumentParser.error\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m   2576\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21merror\u001B[39m(\u001B[38;5;28mself\u001B[39m, message):\n\u001B[1;32m   2577\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"error(message: string)\u001B[39;00m\n\u001B[1;32m   2578\u001B[0m \n\u001B[1;32m   2579\u001B[0m \u001B[38;5;124;03m    Prints a usage message incorporating the message to stderr and\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2583\u001B[0m \u001B[38;5;124;03m    should either exit or raise an exception.\u001B[39;00m\n\u001B[1;32m   2584\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2585\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprint_usage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_sys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstderr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2586\u001B[0m     args \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprog\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprog, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m: message}\n\u001B[1;32m   2587\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexit(\u001B[38;5;241m2\u001B[39m, _(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%(prog)s\u001B[39;00m\u001B[38;5;124m: error: \u001B[39m\u001B[38;5;132;01m%(message)s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m%\u001B[39m args)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/argparse.py:2555\u001B[0m, in \u001B[0;36mArgumentParser.print_usage\u001B[0;34m(self, file)\u001B[0m\n\u001B[1;32m   2553\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2554\u001B[0m     file \u001B[38;5;241m=\u001B[39m _sys\u001B[38;5;241m.\u001B[39mstdout\n\u001B[0;32m-> 2555\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_print_message\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_usage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/argparse.py:2566\u001B[0m, in \u001B[0;36mArgumentParser._print_message\u001B[0;34m(self, message, file)\u001B[0m\n\u001B[1;32m   2564\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2565\u001B[0m     file \u001B[38;5;241m=\u001B[39m _sys\u001B[38;5;241m.\u001B[39mstderr\n\u001B[0;32m-> 2566\u001B[0m \u001B[43mfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/ipykernel/iostream.py:679\u001B[0m, in \u001B[0;36mOutStream.write\u001B[0;34m(self, string)\u001B[0m\n\u001B[1;32m    677\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    678\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI/O operation on closed file\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 679\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m    681\u001B[0m is_child \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_master_process()\n\u001B[1;32m    682\u001B[0m \u001B[38;5;66;03m# only touch the buffer in the IO thread to avoid races\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: I/O operation on closed file"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- 1) Permutation-Importance ---\n",
    "base_nll, deltas = perm_importance(flow_model, Y_valid, X_valid, names_in, repeats=PERM_REPEATS, bs=BATCH_SIZE_EVAL, use_amp=USE_AMP, device=DEVICE)\n",
    "topk, all_rows = topk_by_delta(deltas, k=min(TOPK, len(names_in)))\n",
    "\n",
    "print(f\"Base NLL: {base_nll:.6f}\")\n",
    "rows = [(n, f\"{m:.6f}\", f\"{s:.6f}\") for (n,m,s) in [(n,)+deltas[n] for n in deltas]]\n",
    "rows.sort(key=lambda r: float(r[1]), reverse=True)\n",
    "print_table(rows, headers=[\"Feature\", \"ΔNLL (mean)\", \"ΔNLL (std)\"])\n",
    "\n",
    "# Plot (alle Features)\n",
    "barplot_perm_importance(deltas, title=\"Permutation Importance (ΔNLL)\")"
   ],
   "id": "b7647669be0b9256"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- 2) Gradienten-Sensitivität ---\n",
    "grads = context_grad_sensitivity(flow_model, Y_valid, X_valid, bs=2048, device=DEVICE).numpy()\n",
    "rows = list(zip(names_in, [f\"{g:.6e}\" for g in grads]))\n",
    "rows.sort(key=lambda t: float(t[1]), reverse=True)\n",
    "print_table(rows, headers=[\"Feature\", \"⟨|∂ log p/∂x_j|⟩\"])\n",
    "barplot_grad_sensitivity(names_in, grads, title=\"Gradient Sensitivity ⟨|∂ log p/∂x_j|⟩\")"
   ],
   "id": "83918407c622505"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- 3) Counterfactual‑Sampling auf Top-K Features ---\n",
    "# Wähle Top-K nach ΔNLL\n",
    "top_features = [name for name,_,_ in topk]\n",
    "print(\"Top-Features (nach ΔNLL):\", top_features)\n",
    "\n",
    "subset = X_valid[: min(10000, X_valid.size(0))].clone()\n",
    "for name in top_features:\n",
    "    j = names_in.index(name)\n",
    "    mean_shift, var_shift = counterfactual_shift(flow_model, subset, j, delta=COUNTERFACTUAL_DELTA, device=DEVICE)\n",
    "    print(f\"\\nFeature: {name} (Δx={COUNTERFACTUAL_DELTA})\")\n",
    "    print(\"Δ mean(Y):\", mean_shift.numpy())\n",
    "    print(\"Δ var(Y): \", var_shift.numpy())\n",
    "    mean_var_shift_plot(mean_shift, var_shift, out_names=names_out, title=f\"Counterfactual Shift: {name} (Δx={COUNTERFACTUAL_DELTA})\")"
   ],
   "id": "6afce8d891fc879d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- 4) All‑Shuffle Sanity Check ---\n",
    "nll_all_shuffle = all_shuffle_nll(flow_model, Y_valid, X_valid, bs=BATCH_SIZE_EVAL, use_amp=USE_AMP, device=DEVICE)\n",
    "print(f\"NLL (all-shuffle contexts): {nll_all_shuffle:.6f}  |  Base NLL: {base_nll:.6f}  |  Δ = {nll_all_shuffle - base_nll:.6f}\")"
   ],
   "id": "9e7014c7317818d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
