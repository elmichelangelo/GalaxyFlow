{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gaNdalF Flow — Conditional Diagnostics Notebook\n",
    "\n",
    "Dieses Notebook ergänzt **Permutation-Importance (ΔNLL)**, **Gradienten-Sensitivität**, **Counterfactual-Sampling** und **All‑Shuffle Sanity Check** für deinen Flow."
   ],
   "id": "dfc95e20dd4d5234"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T07:56:56.643612Z",
     "start_time": "2025-10-13T07:56:53.595854Z"
    }
   },
   "source": [
    "import os, sys, math, json, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional lokal:\n",
    "USE_SEABORN = False\n",
    "if USE_SEABORN:\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "\n",
    "from Handler import fnn, get_os, unsheared_shear_cuts, unsheared_mag_cut, LoggerHandler, calc_color\n",
    "from gandalf import gaNdalF\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ],
   "id": "a70018bc228747f7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T07:57:17.648647Z",
     "start_time": "2025-10-13T07:57:17.629133Z"
    }
   },
   "source": [
    "def load_config_pair(system_path):\n",
    "    now = datetime.now()\n",
    "    if get_os() == \"Mac\":\n",
    "        cfg_cls_name = \"MAC_run_classifier.cfg\"\n",
    "        cfg_flow_name = \"MAC_run_flow.cfg\"\n",
    "    elif get_os() == \"Linux\":\n",
    "        cfg_cls_name = \"LMU_run_classifier.cfg\"\n",
    "        cfg_flow_name = \"LMU_run_flow.cfg\"\n",
    "    else:\n",
    "        raise RuntimeError(\"Undefined operating system\")\n",
    "\n",
    "    with open(f\"{system_path}/conf/{cfg_cls_name}\", 'r') as fp:\n",
    "        cfg_cls = yaml.safe_load(fp)\n",
    "    with open(f\"{system_path}/conf/{cfg_flow_name}\", 'r') as fp:\n",
    "        cfg_flow = yaml.safe_load(fp)\n",
    "\n",
    "    now_str = now.strftime('%Y-%m-%d_%H-%M')\n",
    "    cfg_cls['RUN_DATE']  = now_str\n",
    "    cfg_flow['RUN_DATE'] = now_str\n",
    "    return cfg_cls, cfg_flow\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(sys.path[0])\n",
    "classifier_cfg, flow_cfg = load_config_pair(PROJECT_ROOT)\n",
    "\n",
    "log_lvl = logging.INFO\n",
    "if flow_cfg.get(\"LOGGING_LEVEL\") == \"DEBUG\":\n",
    "    log_lvl = logging.DEBUG\n",
    "elif flow_cfg.get(\"LOGGING_LEVEL\") == \"ERROR\":\n",
    "    log_lvl = logging.ERROR\n",
    "\n",
    "run_flow_logger = LoggerHandler(\n",
    "    logger_dict={\"logger_name\": \"run_flow logger\",\n",
    "                 \"info_logger\": flow_cfg['INFO_LOGGER'],\n",
    "                 \"error_logger\": flow_cfg['ERROR_LOGGER'],\n",
    "                 \"debug_logger\": flow_cfg['DEBUG_LOGGER'],\n",
    "                 \"stream_logger\": flow_cfg['STREAM_LOGGER'],\n",
    "                 \"stream_logging_level\": log_lvl},\n",
    "    log_folder_path=f\"{flow_cfg['PATH_OUTPUT']}/\"\n",
    ")"
   ],
   "id": "b301da384b932296",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T08:09:23.475245Z",
     "start_time": "2025-10-13T07:57:20.611126Z"
    }
   },
   "source": [
    "flow_model = gaNdalF(run_flow_logger, classifier_cfg=classifier_cfg, flow_cfg=flow_cfg)\n",
    "df_gandalf, df_balrog = flow_model.run_flow()\n",
    "\n",
    "df_gandalf = calc_color(df_gandalf, colors=flow_cfg['COLORS_FLOW'], column_name=\"unsheared/mag\")\n",
    "df_balrog  = calc_color(df_balrog,  colors=flow_cfg['COLORS_FLOW'], column_name=\"unsheared/mag\")\n",
    "\n",
    "df_gandalf_cut = unsheared_mag_cut(unsheared_shear_cuts(df_gandalf.copy()))\n",
    "df_balrog_cut  = unsheared_mag_cut(unsheared_shear_cuts(df_balrog.copy()))"
   ],
   "id": "ea14972dafcef44f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.10.2025 09:57:20 - Message: Init gaNdalF - Logger name: run_flow logger stream - Logger level: INFO\n",
      "13.10.2025 09:57:20 - Message: Init GalaxyDataset - Logger name: run_flow logger stream - Logger level: INFO\n",
      "13.10.2025 09:57:20 - Message: Load 20250927_balrog_test_3501063_nf.pkl data set - Logger name: run_flow logger stream - Logger level: INFO\n",
      "13.10.2025 09:57:23 - Message: shape dataset: (3501063, 33) - Logger name: run_flow logger stream - Logger level: INFO\n",
      "13.10.2025 09:57:23 - Message: Sample 1500000 random data from test data set - Logger name: run_flow logger stream - Logger level: INFO\n",
      "13.10.2025 09:57:23 - Message: Use 20250927_StandardScalers_nf.pkl to scale data - Logger name: run_flow logger stream - Logger level: INFO\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m flow_model \u001B[38;5;241m=\u001B[39m gaNdalF(run_flow_logger, classifier_cfg\u001B[38;5;241m=\u001B[39mclassifier_cfg, flow_cfg\u001B[38;5;241m=\u001B[39mflow_cfg)\n\u001B[0;32m----> 2\u001B[0m df_gandalf, df_balrog \u001B[38;5;241m=\u001B[39m \u001B[43mflow_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_flow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m df_gandalf \u001B[38;5;241m=\u001B[39m calc_color(df_gandalf, colors\u001B[38;5;241m=\u001B[39mflow_cfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCOLORS_FLOW\u001B[39m\u001B[38;5;124m'\u001B[39m], column_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsheared/mag\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m df_balrog  \u001B[38;5;241m=\u001B[39m calc_color(df_balrog,  colors\u001B[38;5;241m=\u001B[39mflow_cfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCOLORS_FLOW\u001B[39m\u001B[38;5;124m'\u001B[39m], column_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsheared/mag\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/gandalf/gaNdalF.py:353\u001B[0m, in \u001B[0;36mgaNdalF.run_flow\u001B[0;34m(self, data_frame)\u001B[0m\n\u001B[1;32m    351\u001B[0m         n_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflow_data)\n\u001B[1;32m    352\u001B[0m         y_low \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflow_model\u001B[38;5;241m.\u001B[39msample(n_samples, cond_inputs\u001B[38;5;241m=\u001B[39mc_low_t\u001B[38;5;241m.\u001B[39mrepeat(n_samples, \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m--> 353\u001B[0m         y_high \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc_high_t\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    355\u001B[0m     arr_gandalf_output \u001B[38;5;241m=\u001B[39m y_low  \u001B[38;5;66;03m# self.flow_model.sample(len(input_data), cond_inputs=input_data).detach()\u001B[39;00m\n\u001B[1;32m    357\u001B[0m output_data_np \u001B[38;5;241m=\u001B[39m arr_gandalf_output\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/Handler/flow.py:294\u001B[0m, in \u001B[0;36mFlowSequential.sample\u001B[0;34m(self, num_samples, noise, cond_inputs)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cond_inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    293\u001B[0m     cond_inputs \u001B[38;5;241m=\u001B[39m cond_inputs\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mto(dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m--> 294\u001B[0m samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minverse\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m samples\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/Handler/flow.py:277\u001B[0m, in \u001B[0;36mFlowSequential.forward\u001B[0;34m(self, inputs, cond_inputs, mode, logdets)\u001B[0m\n\u001B[1;32m    275\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m cond_inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    276\u001B[0m             cond_inputs \u001B[38;5;241m=\u001B[39m cond_inputs\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m--> 277\u001B[0m         inputs, logdet \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    278\u001B[0m         logdets \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m logdet\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inputs, logdets\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/Handler/flow.py:147\u001B[0m, in \u001B[0;36mMADE.forward\u001B[0;34m(self, inputs, cond_inputs, mode)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i_col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(inputs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]):\n\u001B[1;32m    146\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjoiner(x, cond_inputs)\n\u001B[0;32m--> 147\u001B[0m     m, a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    148\u001B[0m     x[:, i_col] \u001B[38;5;241m=\u001B[39m inputs[:, i_col] \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mexp(\n\u001B[1;32m    149\u001B[0m         a[:, i_col]) \u001B[38;5;241m+\u001B[39m m[:, i_col]\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x, \u001B[38;5;241m-\u001B[39ma\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Development/PhD/GalaxyFlow/Handler/flow.py:53\u001B[0m, in \u001B[0;36mMaskedLinear.forward\u001B[0;34m(self, inputs, cond_inputs)\u001B[0m\n\u001B[1;32m     50\u001B[0m inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdev, dtype\u001B[38;5;241m=\u001B[39mdt)\n\u001B[1;32m     51\u001B[0m W \u001B[38;5;241m=\u001B[39m weight \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmask\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdev, dtype\u001B[38;5;241m=\u001B[39mdt)\n\u001B[0;32m---> 53\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# output = F.linear(inputs, self.linear.weight * self.mask, self.linear.bias)\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cond_inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_flow_core(maybe_wrapper):\n",
    "    for name in [\"flow_model\",\"flow\",\"nf\",\"model\",\"flow_nf\",\"flow_core\"]:\n",
    "        if hasattr(maybe_wrapper, name):\n",
    "            obj = getattr(maybe_wrapper, name)\n",
    "            if hasattr(obj, \"log_probs\") and hasattr(obj, \"sample\"):\n",
    "                return obj\n",
    "            # recursive\n",
    "            inner = extract_flow_core(obj)\n",
    "            if inner is not None:\n",
    "                return inner\n",
    "    if hasattr(maybe_wrapper, \"log_probs\") and hasattr(maybe_wrapper, \"sample\"):\n",
    "        return maybe_wrapper\n",
    "    return None\n",
    "\n",
    "flow_core = extract_flow_core(flow_model)\n",
    "assert flow_core is not None, \"Flow-Modell nicht gefunden – bitte extract_flow_core anpassen.\"\n",
    "\n",
    "in_cols  = list(flow_cfg[\"INPUT_COLS\"])\n",
    "out_cols = list(flow_cfg[\"OUTPUT_COLS\"])\n",
    "\n",
    "X_valid = torch.tensor(df_balrog[in_cols].values, dtype=next(flow_core.parameters()).dtype)\n",
    "Y_valid = torch.tensor(df_balrog[out_cols].values, dtype=next(flow_core.parameters()).dtype)\n",
    "\n",
    "DEVICE = flow_cfg.get(\"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "flow_core = flow_core.to(DEVICE).eval()"
   ],
   "id": "ac82058e6f3bbc38"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mean_nll(model, Y, X, bs=4096, use_amp=False, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    tot, n = 0.0, 0\n",
    "    X = X.to(device); Y = Y.to(device)\n",
    "    autocast_ctx = (torch.amp.autocast(device_type=\"cuda\") if (use_amp and device=='cuda') else nullcontext())\n",
    "    for i in range(0, X.size(0), bs):\n",
    "        xb = X[i:i+bs]; yb = Y[i:i+bs]\n",
    "        with autocast_ctx:\n",
    "            nll = -model.log_probs(yb, xb)\n",
    "        tot += nll.sum().item(); n += yb.size(0)\n",
    "    return tot / max(n,1)\n",
    "\n",
    "def perm_importance(model, Y, X, col_names, repeats=3, bs=4096, use_amp=False, device=\"cpu\", rng=None):\n",
    "    base = mean_nll(model, Y, X, bs, use_amp, device)\n",
    "    deltas = {}\n",
    "    Xcpu = X.detach().cpu(); N = Xcpu.shape[0]\n",
    "    import numpy as _np, torch as _torch\n",
    "    rng = _np.random.default_rng(None if rng is None else rng)\n",
    "    for j, name in enumerate(col_names):\n",
    "        incs = []\n",
    "        for _ in range(repeats):\n",
    "            Xperm = Xcpu.clone()\n",
    "            idx = _torch.from_numpy(rng.permutation(N))\n",
    "            Xperm[:, j] = Xperm[idx, j]\n",
    "            inc = mean_nll(model, Y, Xperm.to(device), bs, use_amp, device) - base\n",
    "            incs.append(float(inc))\n",
    "        deltas[name] = (float(_np.mean(incs)), float(_np.std(incs)))\n",
    "    return base, deltas\n",
    "\n",
    "def all_shuffle_nll(model, Y, X, bs=4096, use_amp=False, device=\"cpu\", rng=None):\n",
    "    import numpy as _np, torch as _torch\n",
    "    rng = _np.random.default_rng(None if rng is None else rng)\n",
    "    Xcpu = X.detach().cpu().clone(); N = Xcpu.shape[0]\n",
    "    for j in range(Xcpu.shape[1]):\n",
    "        idx = _torch.from_numpy(rng.permutation(N))\n",
    "        Xcpu[:, j] = Xcpu[idx, j]\n",
    "    return mean_nll(model, Y, Xcpu.to(device), bs, use_amp, device)\n",
    "\n",
    "def context_grad_sensitivity(model, Y, X, bs=2048, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    grads_sum = torch.zeros(X.size(1), device=device); count = 0\n",
    "    for i in range(0, X.size(0), bs):\n",
    "        xb = X[i:i+bs].to(device).detach().requires_grad_(True)\n",
    "        yb = Y[i:i+bs].to(device)\n",
    "        lp = model.log_probs(yb, xb).mean()\n",
    "        g, = torch.autograd.grad(lp, xb, retain_graph=False, create_graph=False)\n",
    "        grads_sum += g.abs().mean(dim=0); count += 1\n",
    "    return (grads_sum / max(count,1)).detach().cpu()\n",
    "\n",
    "@torch.no_grad()\n",
    "def counterfactual_shift(model, X, j, delta, sample_bs=8192, device=\"cpu\"):\n",
    "    model.eval(); N = X.size(0)\n",
    "    Ys = []\n",
    "    for i in range(0, N, sample_bs):\n",
    "        xb = X[i:i+sample_bs].to(device)\n",
    "        Ys.append(model.sample(num_samples=xb.size(0), cond_inputs=xb))\n",
    "    Y0 = torch.cat(Ys, dim=0).cpu()\n",
    "\n",
    "    Xp = X.clone(); Xp[:, j] += delta\n",
    "    Ys = []\n",
    "    for i in range(0, N, sample_bs):\n",
    "        xb = Xp[i:i+sample_bs].to(device)\n",
    "        Ys.append(model.sample(num_samples=xb.size(0), cond_inputs=xb))\n",
    "    Y1 = torch.cat(Ys, dim=0).cpu()\n",
    "\n",
    "    mean_shift = (Y1.mean(dim=0) - Y0.mean(dim=0))\n",
    "    var_shift  = (Y1.var(dim=0, unbiased=False) - Y0.var(dim=0, unbiased=False))\n",
    "    return mean_shift, var_shift"
   ],
   "id": "a78e6cd7f992b542"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE_EVAL = 4096\n",
    "PERM_REPEATS = 2\n",
    "COUNTERFACTUAL_DELTA = 0.1\n",
    "TOPK = min(5, len(in_cols))\n",
    "USE_AMP = False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "base_nll, deltas = perm_importance(flow_core, Y_valid, X_valid, in_cols, repeats=PERM_REPEATS, bs=BATCH_SIZE_EVAL, use_amp=USE_AMP, device=device)\n",
    "print(f\"Base NLL: {base_nll:.6f}\")\n",
    "d_rows = [(name, deltas[name][0], deltas[name][1]) for name in in_cols]\n",
    "d_rows.sort(key=lambda t: t[1], reverse=True)\n",
    "df_perm = pd.DataFrame(d_rows, columns=[\"feature\", \"delta_nll_mean\", \"delta_nll_std\"])\n",
    "display(df_perm.head(10))\n",
    "\n",
    "# Plot ΔNLL\n",
    "names = [r[0] for r in d_rows]; vals = [r[1] for r in d_rows]; errs = [r[2] for r in d_rows]\n",
    "idx = np.arange(len(names))\n",
    "plt.figure(figsize=(max(12, len(names)*0.5), 6))\n",
    "plt.bar(idx, vals, yerr=errs)\n",
    "plt.xticks(idx, names, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"ΔNLL (↑ schlechter)\"); plt.title(\"Permutation Importance (ΔNLL)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Gradienten\n",
    "grads = context_grad_sensitivity(flow_core, Y_valid, X_valid, bs=2048, device=device).numpy()\n",
    "g_rows = list(zip(in_cols, grads))\n",
    "g_rows.sort(key=lambda t: t[1], reverse=True)\n",
    "df_grad = pd.DataFrame(g_rows, columns=[\"feature\", \"grad_sensitivity\"])\n",
    "display(df_grad.head(10))\n",
    "\n",
    "plt.figure(figsize=(max(12, len(in_cols)*0.5), 6))\n",
    "plt.bar(np.arange(len(in_cols)), grads)\n",
    "plt.xticks(np.arange(len(in_cols)), in_cols, rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"⟨|∂ log p/∂x_j|⟩\"); plt.title(\"Gradient Sensitivity\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Counterfactual Top-K\n",
    "top_features = [r[0] for r in d_rows[:TOPK]]\n",
    "subset = X_valid[: min(10000, X_valid.size(0))].clone()\n",
    "for name in top_features:\n",
    "    j = in_cols.index(name)\n",
    "    mean_shift, var_shift = counterfactual_shift(flow_core, subset, j, delta=COUNTERFACTUAL_DELTA, device=device)\n",
    "    print(f\"Feature: {name} (Δx={COUNTERFACTUAL_DELTA})\")\n",
    "    xs = np.arange(len(out_cols))\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(xs, mean_shift.numpy(), marker=\"o\", linestyle=\"-\", label=\"Δ mean(Y)\")\n",
    "    plt.plot(xs, var_shift.numpy(),  marker=\"s\", linestyle=\"--\", label=\"Δ var(Y)\")\n",
    "    plt.xticks(xs, out_cols, rotation=45, ha=\"right\")\n",
    "    plt.legend(); plt.xlabel(\"Output-Dimension\")\n",
    "    plt.title(f\"Counterfactual Shift: {name} (Δx={COUNTERFACTUAL_DELTA})\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# All-Shuffle\n",
    "nll_all_shuffle = all_shuffle_nll(flow_core, Y_valid, X_valid, bs=BATCH_SIZE_EVAL, use_amp=USE_AMP, device=device)\n",
    "print(f\"NLL (all-shuffle): {nll_all_shuffle:.6f} | Base: {base_nll:.6f} | Δ = {nll_all_shuffle - base_nll:.6f}\")"
   ],
   "id": "3284b5b84ca7152b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ensure_outdir(base_dir, sub=\"diagnostics\"):\n",
    "    outdir = os.path.join(base_dir, sub); os.makedirs(outdir, exist_ok=True); return outdir\n",
    "\n",
    "out_dir = ensure_outdir(flow_cfg[\"PATH_PLOTS\"])\n",
    "df_perm.to_csv(os.path.join(out_dir, \"permutation_importance.csv\"), index=False)\n",
    "df_grad.to_csv(os.path.join(out_dir, \"gradient_sensitivity.csv\"), index=False)\n",
    "print(\"CSV gespeichert unter:\", out_dir)"
   ],
   "id": "1a0aba191ebbb031"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
